{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6c8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataFrame에서 인덱스를 사용해 특정 열 또는 행 지정하기.\n",
    "# 대괄호를 사용해 컬럼명을 지정하거나 슬라이싱 문법으로 행 범위 선택 가능.\n",
    "\n",
    "# 컬럼 선택 문법 (단일 선택 시 Series, 다중 선택 시 DataFrame)\n",
    "# df['column_name']         # Series를 반환함.\n",
    "# df(['col1', 'col2'])      # DataFrame을 반환함.\n",
    "\n",
    "# 행 슬라이싱 문법\n",
    "# df[start:end]             # 'start'부터 'end - 1'값 까지 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74795d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    노트북\n",
      "1    마우스\n",
      "2    키보드\n",
      "3    모니터\n",
      "4    스피커\n",
      "Name: product, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 단일 컬럼 선택 예제 코드\n",
    "sales_data = pd.DataFrame({\n",
    "    'product': ['노트북', '마우스', '키보드', '모니터', '스피커'],\n",
    "    'price': [1200000, 25000, 80000, 350000, 120000],\n",
    "    'quantity': [10, 50, 30, 15, 25],\n",
    "    'category': ['전자제품', '주변기기', '주변기기', '전자제품', '주변기기']\n",
    "})\n",
    "\n",
    "product_series = sales_data['product']          # product column만 단일로 선택. index 번호도 같이 출력되는구나. [] 한 겹으로 감싸기.\n",
    "print(product_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068e7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product    price  quantity\n",
      "0     노트북  1200000        10\n",
      "1     마우스    25000        50\n",
      "2     키보드    80000        30\n",
      "3     모니터   350000        15\n",
      "4     스피커   120000        25\n"
     ]
    }
   ],
   "source": [
    "# 다중 컬럼 선택 예제 코드\n",
    "price_quantity = sales_data[['product', 'price', 'quantity']]       # 여러 column을 선택할 때는 [[]] 두 겹 사용하기.\n",
    "print(price_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a6a2735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product    price  quantity category\n",
      "0     노트북  1200000        10     전자제품\n",
      "1     마우스    25000        50     주변기기\n",
      "2     키보드    80000        30     주변기기\n"
     ]
    }
   ],
   "source": [
    "# 행 슬라이싱 사용하기.\n",
    "firtothr = sales_data[0:3]      # 실제로 0, 1, 2행 3개가 선택됨.\n",
    "print(firtothr)             # column명과 index명이 동시에 출력됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35164b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건부 선택 (Boolean Indexing)\n",
    "# 특정 조건을 만족하는 데이터만 필터링해 추출할 때 사용.\n",
    "\n",
    "# 기본 문법\n",
    "# df[condition]     # 조건을 만족하는 행 선택. condition 위치에조건 입력하기. True or False 중 택.\n",
    "# df.query('condition_string')      # 조건을 나타내는 문자열 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecedda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product    price  quantity category\n",
      "0     노트북  1200000        10     전자제품\n",
      "1     마우스    25000        50     주변기기\n",
      "2     키보드    80000        30     주변기기\n",
      "3     모니터   350000        15     전자제품\n",
      "4     스피커   120000        25     주변기기\n"
     ]
    }
   ],
   "source": [
    "# Boolean Indexing 사용하기.\n",
    "over_10000 = sales_data[sales_data['price'] >= 10000]           # price column의 값들 중 10000 이상인 것을 선택.\n",
    "print(over_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118d0d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product   price  quantity category\n",
      "1     마우스   25000        50     주변기기\n",
      "2     키보드   80000        30     주변기기\n",
      "4     스피커  120000        25     주변기기\n"
     ]
    }
   ],
   "source": [
    "# query method 사용.\n",
    "high_quan = sales_data.query('quantity > 20')           # quantity column의 값이 20을 초과하는 행을 선택.\n",
    "print(high_quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a96568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc과 iloc을 활용한 라벨/위치 기반 선택\n",
    "# loc: 인덱스와 컬럼의 라벨을 기준으로 데이터를 선택함.\n",
    "# iloc: 정수 위치를 기준으로 선택함.\n",
    "# 특정 행과 컬럼의 교집합 영역을 정확히 지정해 데이터를 추출할 때 사용.\n",
    "\n",
    "# 기본 문법\n",
    "# df.loc[row_indexer, column_indexer]       # label 기반 선택 방법\n",
    "# df.iloc[row_indexer, column_indexer]      # 정수 위치 기반 선택 방법.\n",
    "# row_indexer: 행 선택자(라벨명, 슬라이스, 리스트, 불린 마스크)\n",
    "# column_indexer: 컬럼 선택자(컬럼명, 슬라이스, 리스트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0469be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           price  quantity category\n",
      "product                            \n",
      "노트북      1200000        10     전자제품\n",
      "마우스        25000        50     주변기기\n",
      "키보드        80000        30     주변기기\n",
      "모니터       350000        15     전자제품\n",
      "스피커       120000        25     주변기기\n"
     ]
    }
   ],
   "source": [
    "# index 명을 설정하기.\n",
    "sales_data_indexed = sales_data.set_index('product')\n",
    "print(sales_data_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea66ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas의 '.set_index' method\n",
    "# 기존 컬럼을 행 인덱스로 승격시키는 method.\n",
    "# index는 loc 기반 조회/정렬/조인/그룹핑/시계열 처리에서 핵심 축이 되기 때문에 데이터 파이프라인에서 정말 자주 사용함.\n",
    "\n",
    "# 기본 구조\n",
    "# DF.set_index(keys, *, drop=True, append=False, inplace=False, verify_integrity=False)\n",
    "# DataFrame의 index를 기존 컬럼 또는 동일 길이의 배열로 설정함.\n",
    "# 기본적으로 원본을 유지하면서 새 DF를 반환하고, 'inplace=True'면 원본을 수정함. \n",
    "\n",
    "# 왜 index를 바꾸는가?\n",
    "# Pandas에서 index는 단순 '행 번호'가 아닌 '정렬/정합/라벨 기반 선택'의 기준이 되기 때문.\n",
    "# (라벨 기반 조회) 'df.loc[키]' / 'df.loc[(키1, 키2)] (Multiindex)\n",
    "# 'reset_index()'는 'set_index'의 역연산에 가깝게 동작함.\n",
    "# 'reset_index()'는 index를 컬럼으로 내리고 기본 정수 인덱스로 다시 복구함.\n",
    "# 'DataFrame.join()'은 index 또는 key 컬럼으로 결합을 수행함. (key보다는 index join이 더 자연스러움.)\n",
    "\n",
    "# parameter 01: keys\n",
    "# index로 올릴 대상.\n",
    "# 컬럼 이름 1개, 컬럼 이름 리스트, 계산된 결과(array, Series, Index 등)를 사용 가능.\n",
    "# 단, 계산된 결과는 길이가 행 수와 동일해야 함.\n",
    "\n",
    "# parameter 02: drop\n",
    "# 기본값은 True\n",
    "# True: index로 사용한 열을 본문 컬럼에서 제거함.\n",
    "# False: index로도 사용하고 컬럼에도 사용함. (ETL에서 디버깅과 가독성 때문에 가끔 유용함.)\n",
    "\n",
    "# parameter 03: append\n",
    "# 기본값은 False\n",
    "# False: 기존 index를 교체함.\n",
    "# True: 기존 index에 새 key를 추가해 Multiindex로 확장함.\n",
    "\n",
    "# parameter 04: verify_integrity\n",
    "# 기본값은 False\n",
    "# True: 새 index에 중복된 key가 있는지 즉시 검사하고, 존재하면 error를 발생.\n",
    "# False: 중복된 key 유무를 검사하지 않음.\n",
    "# 중복 검사 비용이 발생할 수 있어서 기본이 False.\n",
    "\n",
    "# parameter 05: inplace\n",
    "# 기본값은 False\n",
    "# True: 원본 객체를 수정함.\n",
    "# False: 원본 객체를 수정하지 않음.\n",
    "# Pandas는 Copy-on-Write 방향으로 가고 있어서 True가 항상 진짜 메모리 복사 없이 동작한다고 보긴 어렵다는 설계 논의가 있음.\n",
    "# 그래서 실무에선 보통 할당(다시 대입) 스타일을 더 추구함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1789951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name dept  score        date\n",
      "id                               \n",
      "101   Kim   DS     90  2025-12-29\n",
      "102   Lee   DS     85  2025-12-29\n",
      "103  Park   HR     90  2025-12-30\n",
      "104  Choi   HR     70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 01\n",
    "# 단일 컬럼을 index로 변환.\n",
    "df01 = pd.DataFrame({\n",
    "    'id': [101, 102, 103, 104],\n",
    "    'name': ['Kim', 'Lee', 'Park', 'Choi'],\n",
    "    'dept': ['DS', 'DS', 'HR', 'HR'],\n",
    "    'score': [90, 85, 90, 70],\n",
    "    'date': [\"2025-12-29\", \"2025-12-29\", \"2025-12-30\", \"2025-12-31\"]\n",
    "})\n",
    "\n",
    "df_idx = df01.set_index(\"id\")       # id 컬럼을 index로 설정.\n",
    "print(df_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cd013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  name dept  score        date\n",
      "id                                    \n",
      "101  101   Kim   DS     90  2025-12-29\n",
      "102  102   Lee   DS     85  2025-12-29\n",
      "103  103  Park   HR     90  2025-12-30\n",
      "104  104  Choi   HR     70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 02\n",
    "# 'drop=False' parameter를 사용해 열도 보존하기.\n",
    "df_keep = df01.set_index(\"id\", drop=False)      # drop parameter의 값을 False로 설정해 기존 id 열을 보존시킴과 동시에 index로 설정하기.\n",
    "print(df_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "088b633e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name  score        date\n",
      "dept id                          \n",
      "DS   101   Kim     90  2025-12-29\n",
      "     102   Lee     85  2025-12-29\n",
      "HR   103  Park     90  2025-12-30\n",
      "     104  Choi     70  2025-12-31\n",
      "\n",
      "    name  score        date\n",
      "id                         \n",
      "101  Kim     90  2025-12-29\n",
      "102  Lee     85  2025-12-29\n",
      "\n",
      "name           Choi\n",
      "score            70\n",
      "date     2025-12-31\n",
      "Name: (HR, 104), dtype: object\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 03\n",
    "# 여러 컬럼을 사용해 Multiindex를 만들기.\n",
    "df_mi = df01.set_index([\"dept\", \"id\"])      # []로 여러 개의 행을 감싸기. 앞에 있는 컬럼이 제일 바깥쪽의 index로 설정됨.\n",
    "print(df_mi)\n",
    "\n",
    "# Multiindex 조회하기.\n",
    "print(f\"\\n{df_mi.loc[\"DS\"]}\")               # 1레벨(dept)로 슬라이싱.\n",
    "print(f\"\\n{df_mi.loc[(\"HR\", 104)]}\")        # (dept, id) 튜플로 두 조건을 모두 만족하는 결과값 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba98f863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name  score        date\n",
      "id  dept                         \n",
      "101 DS     Kim     90  2025-12-29\n",
      "102 DS     Lee     85  2025-12-29\n",
      "103 HR    Park     90  2025-12-30\n",
      "104 HR    Choi     70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 04\n",
    "# 'append=True' parameter를 사용해 기존 인덱스에 추가하기\n",
    "df_append = df01.set_index(\"id\").set_index(\"dept\", append=True)     # id 컬럼을 index로 먼저 설정하고, 추가로 .set_index를 사용해 dept 컬럼도 인덱스로 추가. 이 때 dept를 뒤에 추가하기 위해 'append=True' 값을 사용.\n",
    "print(df_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55daf444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  name dept  score        date\n",
      "date                                         \n",
      "2025-12-29  101   Kim   DS     90  2025-12-29\n",
      "2025-12-29  102   Lee   DS     85  2025-12-29\n",
      "2025-12-30  103  Park   HR     90  2025-12-30\n",
      "2025-12-31  104  Choi   HR     70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 05\n",
    "# 계산된 배열 및 Series로 index 만들기.\n",
    "df_dateidx = df01.set_index(pd.to_datetime(df01[\"date\"]))       # pd.to_datetime method를 사용해 문자 및 숫자를 시간 형식의 배열로 변환. \n",
    "print(df_dateidx)\n",
    "\n",
    "# .set_index의 key에 컬럼 이름이 아닌 계산된 Series를 부여.\n",
    "# 그래서 'drop=True'여도 원본의 'date' 컬럼이 그대로 유지됨. 이는 컬럼을 index로 지정한 것이 아니기 때문.\n",
    "# 'keys'가 'label' 또는 'array-like'가 될 수 있다는 규칙을 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c26572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError Index has duplicate keys: Index(['DS', 'HR'], dtype='object', name='dept')\n"
     ]
    }
   ],
   "source": [
    "# .set_index 예제 코드 06\n",
    "# 'verify_integrity=True'로 중복 인덱스 즉시 차단하기.\n",
    "try:\n",
    "    df01.set_index('dept', verify_integrity=True)\n",
    "except Exception as e:\n",
    "    print(type(e).__name__, e)\n",
    "\n",
    "# dept 컬럼에 DS와 HR이 각각 2개씩 들어있어 중복이기 때문에, ValueError가 발생함.\n",
    "# 중복 index가 위험한 pipeline에서 아주 유용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfe9059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dept   id  name  score        date\n",
      "0   DS  101   Kim     90  2025-12-29\n",
      "1   DS  102   Lee     85  2025-12-29\n",
      "2   HR  103  Park     90  2025-12-30\n",
      "3   HR  104  Choi     70  2025-12-31\n",
      "\n",
      "     name dept  score        date\n",
      "id                               \n",
      "101   Kim   DS     90  2025-12-29\n",
      "102   Lee   DS     85  2025-12-29\n",
      "103  Park   HR     90  2025-12-30\n",
      "104  Choi   HR     70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# .set_index method 사용 후 자주 이어지는 method들\n",
    "# .reset_index(): index를 다시 컬럼으로 강등\n",
    "# .set_index()의 역연산을 하는 method.\n",
    "# Multiindex의 일부 레벨만 내리는 것도 가능.\n",
    "df_back = df_mi.reset_index()               # multiindex로 적용한 dept와 id 컬럼을 다시 일반 컬럼으로 변환.\n",
    "print(df_back)\n",
    "\n",
    "# .sort_index(): index를 정렬하기.\n",
    "df02 = df01.set_index(\"id\").sort_index()    # index를 오름차순으로 정렬. (defalut)\n",
    "print(f\"\\n{df02}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c95db521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name_L dept_L  score_L      date_L name_R dept_R  score_R      date_R\n",
      "id                                                                       \n",
      "101    Kim     DS       90  2025-12-29    Kim     DS       90  2025-12-29\n",
      "102    Lee     DS       85  2025-12-29    Lee     DS       85  2025-12-29\n",
      "103   Park     HR       90  2025-12-30   Park     HR       90  2025-12-30\n",
      "104   Choi     HR       70  2025-12-31   Choi     HR       70  2025-12-31\n",
      "\n",
      "     name dept  score        date      date_R\n",
      "id                                           \n",
      "101   Kim   DS     90  2025-12-29  2025-12-29\n",
      "102   Lee   DS     85  2025-12-29  2025-12-29\n",
      "103  Park   HR     90  2025-12-30  2025-12-30\n",
      "104  Choi   HR     70  2025-12-31  2025-12-31\n",
      "\n",
      "    id name_L dept_L  score_L      date_L name_R dept_R  score_R      date_R\n",
      "0  101    Kim     DS       90  2025-12-29    Kim     DS       90  2025-12-29\n",
      "1  102    Lee     DS       85  2025-12-29    Lee     DS       85  2025-12-29\n",
      "2  103   Park     HR       90  2025-12-30   Park     HR       90  2025-12-30\n",
      "3  104   Choi     HR       70  2025-12-31   Choi     HR       70  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# 실무에서 .set_index가 활용되는 case 01\n",
    "# index 기반의 join을 깔끔하게 진행.\n",
    "# df.join()은 index 또는 key 컬럼 기반의 결합을 지원함. key 컬럼을 인덱스로 올려놓고 join하면 코드가 깔끔해짐.\n",
    "# left = df01.set_index(\"id\")\n",
    "# right = df01.set_index(\"id\")\n",
    "# out = left.join(right)\n",
    "\n",
    "# print(out)\n",
    "\n",
    "# 위 코드는 error가 발생함. 완전히 동일한 대상끼리 join을 했기 때문.\n",
    "# join으로 'left의 컬럼 + right의 컬럼'을 할 때 같은 이름이 중복되어 결과 DF의 칼럼명이 충돌함.\n",
    "# 해결 방법 01. 'lsuffix' 또는 'rsuffix' 지정.\n",
    "# 겹치는 컬럼명에 자동으로 접미사가 붙어 충돌이 사라짐.\n",
    "left = df01.set_index(\"id\")\n",
    "right = df02\n",
    "out = left.join(right, lsuffix=\"_L\", rsuffix=\"_R\")\n",
    "\n",
    "print(out)\n",
    "\n",
    "# 해결 방법 02. right에서 추가로 붙일 컬럼만 선택하기.\n",
    "left = df01.set_index(\"id\")\n",
    "right = df02[[\"date\"]]      # 'df02.loc[:, [\"date\"]]'로도 사용 가능.\n",
    "out = left.join(right, rsuffix=\"_R\")        # 겹치는 부분이 없기 때문에 suffix 사용이 필수는 아님.\n",
    "\n",
    "print(f\"\\n{out}\")\n",
    "\n",
    "# 해결 방법 03. merge()로 명시적 join 후 'suffixes' 사용\n",
    "# index 올림 및 내림이 번거롭거나, Key 컬럼 기반 병합을 더 명확히 하고 싶을 때 merge()를 사용.\n",
    "out = df01.merge(df02.reset_index(), on=\"id\", how=\"left\", suffixes=(\"_L\", \"_R\"))\n",
    "print(f\"\\n{out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dec32483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     name dept  score        date          email  risk_score  last_login\n",
      "id                                                                      \n",
      "101   Kim   DS     90  2025-12-29   kim@corp.com        0.12  2025-12-30\n",
      "102   Lee   DS     85  2025-12-29            NaN         NaN         NaN\n",
      "103  Park   HR     90  2025-12-30  park@corp.com        0.35  2025-12-31\n",
      "104  Choi   HR     70  2025-12-31  choi@corp.com        0.80  2025-12-31\n"
     ]
    }
   ],
   "source": [
    "# 실제 다른 DF를 사용해 join을 하는 코드\n",
    "df01 = pd.DataFrame({\n",
    "    'id': [101, 102, 103, 104],\n",
    "    'name': [\"Kim\", \"Lee\", \"Park\", \"Choi\"],\n",
    "    'dept': [\"DS\", \"DS\", \"HR\", \"HR\"],\n",
    "    'score': [90, 85, 90, 70],\n",
    "    'date': [\"2025-12-29\", \"2025-12-29\", \"2025-12-30\", \"2025-12-31\"]\n",
    "})\n",
    "\n",
    "df02 = pd.DataFrame({\n",
    "    \"id\": [101, 103, 104, 105],\n",
    "    \"email\": [\"kim@corp.com\", \"park@corp.com\", \"choi@corp.com\", \"new@corp.com\"],\n",
    "    \"risk_score\": [0.12, 0.35, 0.80, 0.50],\n",
    "    \"last_login\": [\"2025-12-30\", \"2025-12-31\", \"2025-12-31\", \"2025-12-31\"]\n",
    "})\n",
    "\n",
    "left = df01.set_index(\"id\")\n",
    "right = df02.set_index(\"id\")\n",
    "out = left.join(right, how='left', validate='one_to_one')       # validate는 join key가 양쪽에서 유일한지 확인하는 안전 장치.\n",
    "\n",
    "print(out)\n",
    "\n",
    "# 'how=left'를 사용해 df01의 모든 id가 유지됨.\n",
    "# df02에 없는 102는 오른쪽 컬럼들이 NaN으로 채워짐.\n",
    "# df02에만 있는 105는 left join 방식이라서 결과에 나오지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be95d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실무에서 .set_index가 활용되는 case 02\n",
    "# 계층형 집계(부서 -> 사번)용 Multiindex 설계\n",
    "# 부서, 날짜, 환자 ID 등 계층이 있는 key는 Multiindex로 모델링하기 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f6e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실무에서 .set_index가 활용되는 case 03\n",
    "# pipeline에서 inplace 대신 '재대입'을 기본값으로 사용할 때.\n",
    "# Pandas는 'Copy-On-Write' 방향이라 'Inplace=True'가 메모리 및 성능을 항상 보장하진 않음.\n",
    "# 그래서 실무에서는 아래와 같이 새 변수에 할당하는 방식으로 사용함.\n",
    "# df = df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b3037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  name dept  score        date\n",
      "0  101   Kim   DS     90  2025-12-29\n",
      "1  102   Lee   DS     85  2025-12-29\n",
      "2  103  Park   HR     90  2025-12-30\n",
      "3  104  Choi   HR     70  2025-12-31\n",
      "\n",
      "    id          email  risk_score  last_login\n",
      "0  101   kim@corp.com        0.12  2025-12-30\n",
      "1  103  park@corp.com        0.35  2025-12-31\n",
      "2  104  choi@corp.com        0.80  2025-12-31\n",
      "3  105   new@corp.com        0.50  2025-12-31\n",
      "\n",
      "Index(['id', 'name', 'dept', 'score', 'date'], dtype='object')\n",
      "\n",
      "Index(['id', 'email', 'risk_score', 'last_login'], dtype='object')\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{df01}\")\n",
    "print(f\"\\n{df02}\")\n",
    "print(f\"\\n{df01.columns}\")\n",
    "print(f\"\\n{df02.columns}\")\n",
    "print(f\"\\n{df01['id'].duplicated().any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f17f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노트북 가격: 1200000\n"
     ]
    }
   ],
   "source": [
    "# 다시 교재의 내용으로 복귀\n",
    "# loc: 라벨 기반으로 선택하기.\n",
    "notebook_info = sales_data_indexed.loc['노트북', 'price']\n",
    "\n",
    "print(f\"노트북 가격: {notebook_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8dd9486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           price  quantity\n",
      "product                   \n",
      "노트북      1200000        10\n",
      "모니터       350000        15\n"
     ]
    }
   ],
   "source": [
    "# loc으로 여러 데이터를 선택하기.\n",
    "selected_data = sales_data_indexed.loc[['노트북', '모니터'], ['price', 'quantity']]\n",
    "\n",
    "print(f\"{selected_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d6d4d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     price  quantity\n",
      "0  1200000        10\n",
      "2    80000        30\n"
     ]
    }
   ],
   "source": [
    "# iloc 사용\n",
    "# 라벨이 아닌 위치 기반으로 선택.\n",
    "positional_data = sales_data.iloc[[0, 2], [1, 2]]       # 앞의 []는 행, 뒤의 []는 컬럼. 둘 다 index 값을 사용.\n",
    "print(positional_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a20a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 조건 선택\n",
    "# 여러 조건을 동시에 적용해 더 정교한 데이터 필터링을 수행할 때 사용.\n",
    "# 각 조건을 괄호로 묶고, 논리 연산자를 사용해 조건들을 결합함.\n",
    "\n",
    "# 기본 문법\n",
    "# df[(condition01) & (condition02)]         # AND 조건\n",
    "# df[(condition01) | (condition02)]         # OR 조건\n",
    "# df[~condition]                            # NOT 조건\n",
    "# 반환값은 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbb3450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가격이 5만원 이상이면서 수량이 20개인 제품 정보: \n",
      "  product   price  quantity category\n",
      "2     키보드   80000        30     주변기기\n",
      "4     스피커  120000        25     주변기기\n"
     ]
    }
   ],
   "source": [
    "# 다중 조건 선택 예제 코드 01\n",
    "# 가격이 50000원 이상이면서 수량이 20개 이상인 제품 추출\n",
    "filter_product = sales_data[(sales_data['price'] >= 50000) & (sales_data['quantity'] >= 20)]\n",
    "\n",
    "print(f\"가격이 5만원 이상이면서 수량이 20개인 제품 정보: \\n{filter_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "373aa77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전자제품이거나 가격이 3만원 이하인 제품의 정보: \n",
      "  product    price  quantity category\n",
      "0     노트북  1200000        10     전자제품\n",
      "1     마우스    25000        50     주변기기\n",
      "3     모니터   350000        15     전자제품\n"
     ]
    }
   ],
   "source": [
    "# 다중 조건 선택 예제 코드 02\n",
    "# 전자제품이거나 가격이 3만원 이하인 제품의 정보 추출\n",
    "filter02 = sales_data[(sales_data['category'] == '전자제품') | (sales_data['price'] <= 30000)]\n",
    "\n",
    "print(f\"전자제품이거나 가격이 3만원 이하인 제품의 정보: \\n{filter02}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3791d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 별로 데이터 선택하기.\n",
    "# 데이터를 특정 기준으로 그룹화한 후 특정 그룹만 선택하거나, 그룹별로 계산된 결과를 원본 데이터에 적용할 때 사용.\n",
    "# 그룹화는 데이터 분석에서 카테고리별, 지역별, 시간대별 등 특정 기준으로 데이터를 나눠 분석할 때 필수적인 기법.\n",
    "\n",
    "# 기본 문법\n",
    "# df.groupby('column').get_group('group_value')             # 특정 그룹을 선택.\n",
    "# df.groupby('column')['target_column'].transform(func)     # 그룹 별로 변환.\n",
    "\n",
    "# parameter 01. column\n",
    "# 그룹화를 할 기준이 되는 컬럼명\n",
    "\n",
    "# parameter 02. group_value\n",
    "# 선택할 그룹의 값.\n",
    "\n",
    "# parameter 03. target_column\n",
    "# 변환할 대상 컬럼.\n",
    "\n",
    "# parameter 04. func\n",
    "# 적용할 함수\n",
    "\n",
    "# .get_group() method는 특정 그룹에 속하는 모든 행을 DataFrame 형태로 반환함.\n",
    "# .transform() method는 원본 DataFrame과 동일한 크기의 Series를 반환하고, 각 행에 해당 그룹의 계산 결과가 할당됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81850701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카테고리별 그룹화 후 전자제품만 추출하기: \n",
      "  product    price  quantity category\n",
      "0     노트북  1200000        10     전자제품\n",
      "3     모니터   350000        15     전자제품\n"
     ]
    }
   ],
   "source": [
    "# 그룹 별 데이터 선택 예제 코드 01\n",
    "# '.get_group()'으로 카테고리별 그룹화를 진행한 후 전자제품 그룹만 선택하기.\n",
    "category_group = sales_data.groupby('category').get_group('전자제품')\n",
    "\n",
    "print(f\"카테고리별 그룹화 후 전자제품만 추출하기: \\n{category_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ac1666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product    price  quantity category  avg_price\n",
      "0     노트북  1200000        10     전자제품   775000.0\n",
      "1     마우스    25000        50     주변기기    75000.0\n",
      "2     키보드    80000        30     주변기기    75000.0\n",
      "3     모니터   350000        15     전자제품   775000.0\n",
      "4     스피커   120000        25     주변기기    75000.0\n"
     ]
    }
   ],
   "source": [
    "# 그룹 별 데이터 선택 예제 코드 02\n",
    "# '.transform' method를 사용해 각 카테고리별 평균 가격을 원본 데이터에 추가하기.\n",
    "sales_data['avg_price'] = sales_data.groupby('category')['price'].transform('mean')         # 원본 DataFrame에 추가할 컬럼 이름을 설정하고, 'category' 컬럼을 기준으로 그룹화를 진행한 다음 'price' 컬럼에 mean 함수를 사용한 transform method를 적용.\n",
    "\n",
    "print(f\"{sales_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5ca4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터 선택하기.\n",
    "# 시계열 데이터에서 특정 기간, 시간대, 날짜 범위의 데이터를 선택할 때 사용.\n",
    "# index가 'datetime' 형태로 되어 있어야 효과적으로 활용 가능.\n",
    "# 시계열 분석은 주가 데이터, 판매 추이, 온도 변화 등 시간에 따라 변하는 데이터를 다룰 때 필수.\n",
    "\n",
    "# 기본 문법\n",
    "# df[df.index.year == year]                     # 특정 연도를 선택하는 구문. (year는 정수값)\n",
    "# df.between_time(start_time, end_time)         # 시간 범위를 선택하는 구문. (.between_time() method) 'start_time'과 'end_time'은 문자열.\n",
    "# df.loc['start_date':'end_date']               # 날짜 범위를 선택하는 구문. 'start_date'와 'end_date'는 문자열.\n",
    "# 지정된 시간 조건을 만족하는 데이터를 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a893ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sales  returns\n",
      "date                      \n",
      "2024-01-01    100        5\n",
      "2024-01-02    150        8\n",
      "2024-01-03    200       12\n",
      "2024-01-04    120        6\n",
      "2024-01-05    180        9\n",
      "\n",
      "\n",
      "DatetimeIndex(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04',\n",
      "               '2024-01-05'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "# 시계열 데이터 예제 코드 01\n",
    "# 먼저 날짜 컬럼을 index로 설정해야 날짜 기반 선택과 filtering이 가능해짐.\n",
    "dates = pd.date_range('2024-01-01', periods=5, freq='D')        # 'periods': 만들 날짜의 개수 / 'freq': 연/일/월 중 택. (default는 D(day))\n",
    "time_series_data = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'sales': [100, 150, 200, 120, 180],\n",
    "    'returns': [5, 8, 12, 6, 9]\n",
    "})\n",
    "\n",
    "time_series_data.set_index('date', inplace=True)            # date를 index로 적용. 그리고 원본 객체를 수정하기 위해 'inplace=True' 옵션을 사용하고, 새 변수에 할당하지 않음.\n",
    "\n",
    "print(time_series_data)\n",
    "\n",
    "print(f\"\\n\\n{dates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c92feb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sales  returns\n",
      "date                      \n",
      "2024-01-01    100        5\n",
      "2024-01-02    150        8\n",
      "2024-01-03    200       12\n"
     ]
    }
   ],
   "source": [
    "# 시계열 데이터 예제 코드 02\n",
    "# 특정 날짜 범위를 선택하기.\n",
    "# loc을 사용해서 시작일과 종료일을 모두 포함하는 범위를 반환하기.\n",
    "# 문자열 형태로 날짜를 지정할 수 있어 직관적이고 편리함.\n",
    "# 특정 기간의 매출 분석, 월별 또는 분기별 데이터 추출 등에 사용되는 방법.\n",
    "jan_1to3 = time_series_data.loc['2024-01-01':'2024-01-03']              # '시작일':'종료일' 형식. 종료일은 -1 없이 종료일도 그대로 포함됨.\n",
    "\n",
    "print(jan_1to3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef9f93a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sales  returns\n",
      "date                      \n",
      "2024-01-01    100        5\n",
      "2024-01-02    150        8\n",
      "2024-01-03    200       12\n",
      "2024-01-04    120        6\n",
      "2024-01-05    180        9\n"
     ]
    }
   ],
   "source": [
    "# 시계열 데이터 예제 코드 03\n",
    "# 연도 기준으로 filtering 하기.\n",
    "# index의 year 속성을 사용하면 특정 연도의 데이터만 선택 가능.\n",
    "# 여러 해에 걸친 데이터에서 연도별 비교 분석에 유용.\n",
    "# month, day, dayofweek 등의 속성을 사용해 월별, 일별, 요일별 filtering도 가능.\n",
    "year_2024 = time_series_data[time_series_data.index.year == 2024]               # DF에서 index 중 year 속성이 2024 인 것만 filtering 해서 추출.\n",
    "\n",
    "print(year_2024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Latest Python",
   "language": "python",
   "name": "latest-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
